<html lang="en-GB">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance</title>
    <meta name="description"
        content="We've presented VideoGameQA-Bench, a comprehensive benchmark for evaluating Vision-Language Models in video game QA tasks.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance"
        property="og:title">
    <meta content="A comprehensive benchmark for evaluating Vision-Language Models in video game QA tasks."
        property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description"
        content="VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance. A comprehensive benchmark for evaluating Vision-Language Models in video game QA tasks.">
    <meta name="twitter:image:src" content="assets/figures/25AE7184-F49E-4322-98DE-4B558D88BC8B.png">

    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css" />
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script> <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
        <div class="blog-title">
            <div class="blog-intro">
                <div>
                    <h1 class="title">VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality
                        Assurance</h1>
                    <p class="author">Mohammad Reza Taesiri, Abhijay Ghildyal, Saman Zadtootaghaj, Nabajeet Barman,
                        Cor-Paul Bezemer</p>
                    <p class="abstract">
                        With video games now generating the highest revenues in the entertainment industry, optimizing
                        game development workflows has become essential for the sector's sustained growth. Recent
                        advancements in Vision-Language Models (VLMs) offer considerable potential to automate and
                        enhance various aspects of game development, particularly Quality Assurance (QA), which remains
                        one of the industry's most labor-intensive processes with limited automation options. To
                        accurately evaluate the performance of VLMs in video game QA tasks and determine their
                        effectiveness in handling real-world scenarios, there is a clear need for standardized
                        benchmarks, as existing benchmarks are insufficient to address the specific requirements of this
                        domain. To bridge this gap, we introduce VideoGameQA-Bench, a comprehensive benchmark that
                        covers a wide array of game QA activities, including visual unit testing, visual regression
                        testing, needle-in-a-haystack tasks, glitch detection, and bug report generation for both images
                        and videos of various games.
                    </p>

                </div>

                <div class="info">
                    <div>
                        <a href="https://arxiv.org" class="button icon"
                            style="background-color: rgba(255, 255, 255, 0.2)"> Paper <i
                                class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp;
                        <a href="https://github.com" class="button icon"
                            style="background-color: rgba(255, 255, 255, 0.2)">Artifacts <i
                                class="fa-solid fa-file-code"></i></a>
                        &nbsp;&nbsp;
                        <a href="https://huggingface.co/datasets/taesiri/VideoGameQA-Bench" class="button icon"
                            style="background-color: rgba(255, 255, 255, 0.2)">Dataset <i
                                class="fa-solid fa-database"></i></a>
                    </div>
                </div>
            </div>

            <div class="blog-cover">
                <img class="foreground" src="assets/figures/25AE7184-F49E-4322-98DE-4B558D88BC8B.png">
                <img class="background" src="assets/figures/25AE7184-F49E-4322-98DE-4B558D88BC8B.png">
            </div>
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1>
            Introduction
        </h1>
        <p>
            The global video game industry continues to expand rapidly, with its market value projected to reach $257
            billion by
            2028. Alongside this substantial growth, the process of developing high-quality video games remains
            inherently
            complex and demanding. A critical challenge within game development is to ensure visual quality and
            consistency
            through a rigorous visual testing and quality assurance (QA) process. Automation of visual QA tasks remains
            particularly challenging, and currently, most visual QA relies heavily on manual inspection, making the
            process
            time-consuming, costly, labor-intensive, and prone to human error.
        </p>

        <br>

        <p>
            The visual QA process for video games can generally be abstracted into three main types of tasks:
        </p>
        <br>
        <li style="margin-left: 2em;">
            <strong>Verifying scene integrity</strong> by comparing the visual representation of scenes against
            intended
            configurations and known reference states, such as an oracle or previously rendered versions of the same
            scenes.
        </li>
        <li style="margin-left: 2em;">
            <strong>Detecting glitches</strong> through open-ended exploration—these glitches are unintended
            gameplay or
            visual artifacts without specific reference points, requiring testers to rely on common sense and
            general
            knowledge for detection.
        </li>
        <li style="margin-left: 2em;">
            <strong>Systematically reporting and documenting</strong> all identified glitches, ensuring developers
            receive
            clear and actionable information to address problems effectively during game development.
        </li>
        </ol>

        <br>

        <p>
            Recent advancements in vision-language models (VLMs) present promising opportunities to automate and
            significantly
            enhance the efficiency of video game QA. However, progress in applying VLMs to game QA has been limited by
            the lack
            of standardized benchmarks. Current multimodal benchmarks tend to focus heavily on complex mathematical or
            textual
            reasoning tasks, overlooking essential visual comprehension tasks fundamental to video game QA. Similarly,
            existing
            game-specific benchmarks often represent only narrow aspects of QA tasks, thus inadequately evaluating and
            tracking
            VLM performance across diverse QA scenarios.
        </p>
    </div>


    <div class="container blog main" id="blog-main">
        <h1>
            Our Contributions
        </h1>
        <p>
            In this paper, we introduce <strong>GameQA-Benchmark</strong>, a benchmark designed to fill the gap in
            evaluating
            VLMs for video game QA. Our key findings and contributions are as follows:
        </p>
        <br>

        <ol style="margin-left: 2em;">
            <li>
                We present <strong>VideoGameQA-Benchmark</strong> featuring 9 distinct tasks and a large set of
                questions
                designed
                considering real-world video game development scenarios, such as visual unit testing, regression
                testing, UI
                validation, video needle-in-a-haystack, and glitch detection.
            </li>
            <li>
                While VLMs show promising performance on various multimodal benchmarks and can function as OCR systems,
                they
                perform poorly at detecting fine details required for accurate scene understanding and parsing complex
                UI
                elements.
            </li>
            <li>
                Frontier VLMs show good performance on the glitch detection task using images (up to 82.8%) and videos
                (up to
                78.1%); however, all struggle when it comes to glitches related to body configuration, intricate object
                clipping, and common-sense reasoning.
            </li>
            <li>
                Visual regression testing remains one of the most challenging tasks for VLMs.
            </li>
            <li>
                Locating specific glitch moments in videos remains a challenge, both in detecting and accurately
                pinpointing the
                glitch.
            </li>
            <li>
                Frontier VLMs can generate useful bug reports for up to 50% of real-world glitches, providing accurate
                and
                descriptive summaries of the glitches.
            </li>
        </ol>
    </div>


    <div class="container blog main">
        <h1>
            VideoGameQA-Bench
        </h1>
        <p>
            We designed <strong>VideoGameQA-Benchmark</strong>'s tasks by simulating realistic QA scenarios encountered
            during actual video game development. However, to make the benchmark more relevant for future QA automation
            tasks, we also included tasks that may challenge current software engineering practices while also remaining
            highly
            relevant. The table below provides an overview of the contents of each task in the benchmark.
            In summary, <strong>VideoGameQA-Benchmark</strong> contains 2,236 image-based samples and 1,200
            video-based
            samples sourced from more than 800 games and 9 synthetic game scenes.
        </p>

    </div>





    <div class="container blog main">
        <h1>
            Image-based Tasks
        </h1>
        <h2>Visual Unit Testing</h2>
        <p>
            Visual unit tests verify visual attributes including presence, placement, positioning, colors, conditions,
            and
            other relevant properties of various image elements.
        </p>
    </div>


    <div class="container blog main gray slide-container">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu-visual-unit-test">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>


        <div class="slide-content" , style="display: block;">
            <img src="assets/samples/visual_unit_test/eyes.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>How many of Spider-Man's and Black Cat's eye areas, including those covered by their masks, are
                    visible in the
                    image?
                </p>
                <br>
                <p>Provide your answer in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
    "spiderman_eyes_visible": 0,
    "black_cat_eyes_visible": 0
}</code></pre>
            </div>

        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/visual_unit_test/bird.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>Please provide the values of the dice in the topmost row from left to right, and return them as a
                    JSON list.
                </p>
                <br>

                <ol style="margin-left: 2em;">
                    <li>How many birds are visible inside the room (including inside the cage)?</li>
                    <li>How many birds are visible outside the window?</li>
                    <li>Is the birdcage door open?</li>
                    <li>What is the primary color of the bird inside the cage?</li>
                    <li>Is there a piece of wood leaning on the inside windowsill?</li>
                    <li>What is the main color of the blossoms seen outside the window?</li>
                    <li>Is the wallpaper on the left wall patterned?</li>
                    <li>Where is the grey bird positioned?</li>
                </ol>
                <br>

                <p>Provide your answer in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
    "birds_inside_count": 0, // Integer count
    "birds_outside_count": 0, // Integer count
    "birdcage_door_open": false, // true or false
    "bird_in_cage_color": "", // options: ["yellow", "grey", "blue", "brown"]
    "wood_on_sill_present": false, // true or false
    "blossom_color": "", // options: ["pink", "white", "yellow", "red"]
    "left_wallpaper_patterned": false, // true or false
    "grey_bird_location": "" // options: ["inside cage", "on windowsill", "outside window", "on floor"]
}
                </code></pre>
            </div>
        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/visual_unit_test/car.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>Based on the image answer the following questions:</p>

                <ol style="margin-left: 2em;">
                    <li>What is the primary color of the rally car?</li>
                    <li>Is the driver-side door of the car open or closed?</li>
                    <li>What number is displayed in large font on the car's door?</li>
                    <li>What brand name is visible on the yellow decal above the 'elf' logo on the car's side?</li>
                    <li>Is there a coiled orange air hose hanging from the ceiling on the left side?</li>
                    <li>What type of pattern is on the floor directly beneath the car?</li>
                    <li>Is there a screen or monitor mounted on the wall displaying graphs?</li>
                </ol>

                <p>Provide your answer in the following JSON format:</p>

                <pre><code class="javascript">{
    "car_primary_color": "", // options: ["light blue", "dark blue", "white", "red", "black"]
    "driver_door_state": "", // options: ["open", "closed"]
    "car_door_number": 0, // Integer value
    "yellow_decal_brand": "", // String value representing the text
    "coiled_hose_visible": false, // true or false
    "floor_pattern": "", // options: ["plain", "checkered", "tiled", "textured_metal"]
    "wall_monitor_visible": false // true or false
}
                </code></pre>
            </div>
        </div>


        <p class="caption">
            Sample from the Visual Unit Testing task.
        </p>
    </div>


    <div class="container blog main">
        <h2>UI Unit Testing</h2>
        <p>
            UI (visual) unit tests verify in-game UI elements such as menus, subtitles, heads-up displays (HUDs), and
            interface components like graphs and charts. We simulate the UI unit testing tasks by asking the
            vision-language
            model questions about game screenshots.
        </p>
    </div>


    <div class="container blog main gray slide-container">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu-ui-unit">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>


        <div class="slide-content" , style="display: block;">
            <img src="assets/samples/ui_test/dashboard.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>Read the dashboard and fill the JSON values below:</p>
                <br>
                <pre><code class="javascript">{
    "tire_pressure": {
        "front_left": 0,
        "front_right": 0,
        "rear_left": 0,
        "rear_right": 0
    },
    "brake_temps": {
        "front_left": 0,
        "front_right": 0,
        "rear_left": 0,
        "rear_right": 0
    },
    "break_bias": 0,
    "break_sl": 0,
    "settings": {
        "map": 0,
        "mix": 0,
        "tc1": 0,
        "tc2": 0
    },
    "gear": 0,
    "rpm": 0,
    "speed_mph": 0
}
                </code></pre>
            </div>

        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/ui_test/dicegrid.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>Please provide the values of the dice in the topmost row from left to right, and return them as a
                    JSON list.
                </p>
                <br>
            </div>
        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/ui_test/inventory.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>Based on the image, extract the list of weapons (single word) and return it in the following JSON
                    format:
                </p>

                <pre><code class="javascript">{ "items": ["weapon"] }</code></pre>
            </div>
        </div>


        <p class="caption">
            Sample from the UI Unit Testing task.
        </p>
    </div>







    <div class="container blog main">
        <h2>Visual Regression Testing</h2>
        <p>
            Visual regression tests check for unintended visual changes after a change to the game. A simple
            pixel-by-pixel
            comparison of two screenshots is not sufficient, as some variations (e.g., because of character
            customization or
            weather conditions in the game) may be acceptable.
            Visual regressions may occur in cinematic parts of the game, such as cutscenes that have a defined sequence
            flow. We simulate this task by asking the VLM to compare whether two screenshots are similar, taking into
            account the specified acceptable or unacceptable variations.
        </p>
    </div>

    <div class="container blog main gray extra-large">
        <div class="columns-2">
            <img-comparison-slider class="slider-container white">
                <figure slot="first" class="before">
                    <img src="assets/samples/regression_samples/vr_1_1.jpg">
                    <figcaption class="white">Image Version 1</figcaption>
                </figure>
                <figure slot="second" class="after">
                    <img src="assets/samples/regression_samples/vr_1_2.jpg">
                    <figcaption class="white">Image Version 2</figcaption>
                </figure>
            </img-comparison-slider>
            <img-comparison-slider class="slider-container white">
                <figure slot="first" class="before">
                    <img src="assets/samples/regression_samples/vr_2_1.jpg">
                    <figcaption class="white">Image Version 1</figcaption>
                </figure>
                <figure slot="second" class="after">
                    <img src="assets/samples/regression_samples/vr_2_2.jpg">
                    <figcaption class="white">Image Version 2</figcaption>
                </figure>
            </img-comparison-slider>

        </div>
        <br>
        <div class="columns-2">

            <img-comparison-slider class="slider-container white">
                <figure slot="first" class="before">
                    <img src="assets/samples/regression_samples/31.jpg">
                    <figcaption class="white">Image Version 1</figcaption>
                </figure>
                <figure slot="second" class="after">
                    <img src="assets/samples/regression_samples/32.jpg">
                    <figcaption class="white">Image Version 2</figcaption>
                </figure>
            </img-comparison-slider>
            <img-comparison-slider class="slider-container white">
                <figure slot="first" class="before">
                    <img src="assets/samples/regression_samples/image_012_0000.jpeg">
                    <figcaption class="white">Image Version 1</figcaption>
                </figure>
                <figure slot="second" class="after">
                    <img src="assets/samples/regression_samples/image_017_0000.jpeg">
                    <figcaption class="white">Image Version 2</figcaption>
                </figure>
            </img-comparison-slider>
        </div>

        <p class="caption">
            Sample from the Visual Regression Testing task.
        </p>
    </div>

    <div class="container blog main">
        <h2>Glitch Detection</h2>
        <p>
            Glitch detection is the process of identifying unintended visual errors, such as rendering issues, clipping,
            or
            physics/logical bugs that express themselves visually. We simulate this task by asking the VLM whether
            glitch
            and glitch-free images contain a glitch.
        </p>
    </div>

    <div class="container blog main gray slide-container">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu-glitch-detection">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>


        <div class="slide-content" , style="display: block;">
            <img src="assets/samples/glitch_detection/gd1.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>
                    You are a helpful assistant analyzing video game images and screenshots for glitches. You will be
                    given a screenshot
                    from a video game, and your job is to analyze the screenshot and determine whether it contains a
                    glitch.
                </p>
                <br>
                <p>
                    Provide your answer in the following format:
                </p> <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of why you think a glitch is present",
"glitch_detected": true or false,
"description_of_glitch": "Description of the glitch if detected else empty string"
}</code></pre>
            </div>

        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/glitch_detection/gd2.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>
                    You are a helpful assistant analyzing video game images and screenshots for glitches. You will be
                    given a screenshot
                    from a video game, and your job is to analyze the screenshot and determine whether it contains a
                    glitch.
                </p>
                <br>
                <p>
                    Provide your answer in the following format:
                </p> <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of why you think a glitch is present",
"glitch_detected": true or false,
"description_of_glitch": "Description of the glitch if detected else empty string"
}</code></pre>
            </div>
        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/glitch_detection/gd3.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>
                    You are a helpful assistant analyzing video game images and screenshots for glitches. You will be
                    given a screenshot
                    from a video game, and your job is to analyze the screenshot and determine whether it contains a
                    glitch.
                </p>
                <br>
                <p>
                    Provide your answer in the following format:
                </p> <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of why you think a glitch is present",
"glitch_detected": true or false,
"description_of_glitch": "Description of the glitch if detected else empty string"
}</code></pre>
            </div>
        </div>


        <p class="caption">
            Sample from the Glitch Detection task.
        </p>
    </div>


    <div class="container blog main">
        <h2>Parametric Clipping Detection</h2>
        <p>
            Given the common occurrence of clipping in games, our benchmark includes a dedicated task to evaluate a
            model's
            ability to detect such glitches. In this task, images feature an object (e.g., a cube, sphere, or character)
            positioned at varying distances from a human character — from far apart to fully overlapping/clipping. The
            VLM
            is asked whether it detects clipping across each of these distances.
        </p>
    </div>

    <div class="container blog extra-large gray">
        <img src="clarity/images/prismer.png" alt="Parametric Clipping Detection Sample">
        <p class="caption">
            Sample from the Parametric Clipping Detection task.
        </p>
    </div>

    <div class="container blog main">
        <h2>Bug Report Generation</h2>
        <p>
            In addition to testing and detection tasks, a potential application of VLMs is to assist QA engineers with
            writing reports for detected bugs. We simulate this task by asking the VLM to write a description of a
            glitch
            image that can be used in a bug report.
        </p>


    </div>

    <div class="container blog main gray slide-container">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu-bug-report">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>


        <div class="slide-content" , style="display: block;">
            <img src="assets/samples/bug_report/bgr_1.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>You are a video game quality assurance assistant who analyzes screenshots to identify and document
                    visual glitches. When presented with an image, carefully examine it for any graphical bugs or
                    rendering issues.</p>

                <br>
                <p>Provide your analysis in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of what you observe and why it appears to be a glitch",
"bug_report_title": "A clear, concise title summarizing the issue",
"bug_report_description": "Detailed description of the visual bug, including its appearance and potential impact on
gameplay",
"affected_item": "The specific game element (character, object, environment, UI) affected by the glitch"
}</code></pre>
            </div>

        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/bug_report/bgr_2.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>You are a video game quality assurance assistant who analyzes screenshots to identify and document
                    visual glitches. When presented with an image, carefully examine it for any graphical bugs or
                    rendering issues.</p>

                <br>
                <p>Provide your analysis in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of what you observe and why it appears to be a glitch",
"bug_report_title": "A clear, concise title summarizing the issue",
"bug_report_description": "Detailed description of the visual bug, including its appearance and potential impact on
gameplay",
"affected_item": "The specific game element (character, object, environment, UI) affected by the glitch"
}</code></pre>
            </div>
        </div>

        <div class="slide-content" , style="display: none;">
            <img src="assets/samples/bug_report/bgr_3.jpg" style="width: 100%;">


            <div style="margin-top: 1em; font-size: small;">
                <p>You are a video game quality assurance assistant who analyzes screenshots to identify and document
                    visual glitches. When presented with an image, carefully examine it for any graphical bugs or
                    rendering issues.</p>
                <br>

                <p>Provide your analysis in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of what you observe and why it appears to be a glitch",
"bug_report_title": "A clear, concise title summarizing the issue",
"bug_report_description": "Detailed description of the visual bug, including its appearance and potential impact on
gameplay",
"affected_item": "The specific game element (character, object, environment, UI) affected by the glitch"
}</code></pre>
            </div>
        </div>


        <p class="caption">
            Sample from the Bug Report Generation task.
        </p>
    </div>







    <div class="container blog main">
        <h1>Video-based Tasks</h1>
        <h2>Glitch Detection (Video)</h2>
        <p>
            Glitch detection in videos can be used to verify autonomous gameplay sessions from bots. Detecting glitches
            in
            videos is significantly more complex due to challenges such as analyzing motion patterns, and may require
            identifying transient glitches that appear only briefly in a few frames. We simulate this task by asking the
            vision-language model whether it detects a glitch in a video.
        </p>
    </div>

    <div class="container blog extra-large gray">
        <img src="clarity/images/prismer.png" alt="Bug Report Generation Sample">
        <p class="caption">
            Sample from the Glitch Detection (Video) task.
        </p>
    </div>

    <div class="container blog main">
        <h2>Needle-in-a-Haystack (NIAH)</h2>
        <p>
            Needle-in-a-Haystack (NIAH) is a more challenging long-context retrieval version of the glitch detection
            task.
            We simulate this task by asking the vision-language model whether it detects a glitch in a video, and in
            which
            frame the glitch occurs for the first time.
        </p>
    </div>

    <div class="container blog extra-large gray">
        <img src="clarity/images/prismer.png" alt="Bug Report Generation Sample">
        <p class="caption">
            Sample from the Needle-in-a-Haystack (NIAH) task.
        </p>
    </div>

    <div class="container blog main">
        <h2>Bug Report Generation (Video)</h2>
        <p>
            In this task, the vision-language model is asked to provide a description of a glitch video that can be used
            in
            a bug report.
        </p>
    </div>

    <div class="container blog main gray slide-container">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu-bug-report">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>


        <div class="slide-content" , style="display: block;">
            <video src="assets/samples/bug_report_videos/2mjikm.mp4" style="width: 100%;" controls></video>

            <div style="margin-top: 1em; font-size: small;">
                <p>You are a video game quality assurance assistant who analyzes video clips to identify and document
                    visual glitches or strange behaviors. When presented with a video clip, carefully examine it for any
                    graphical bugs, rendering issues, physics anomalies, or unexpected events.</p>

                <br>
                <p>Provide your analysis in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of what you observe and why it appears to be a glitch",
"bug_report_title": "A clear, concise title summarizing the issue",
"bug_report_description": "Detailed description of the visual bug, including its appearance and potential impact on
gameplay",
"affected_item": "The specific game element (character, object, environment, UI) affected by the glitch"
}</code></pre>
            </div>

        </div>

        <div class="slide-content" , style="display: none;">
            <video src="assets/samples/bug_report_videos/1fu6m84.mp4" style="width: 100%;" controls></video>


            <div style="margin-top: 1em; font-size: small;">
                <p>You are a video game quality assurance assistant who analyzes video clips to identify and document
                    visual glitches or strange behaviors. When presented with a video clip, carefully examine it for any
                    graphical bugs, rendering issues, physics anomalies, or unexpected events.</p>

                <br>
                <p>Provide your analysis in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of what you observe and why it appears to be a glitch",
"bug_report_title": "A clear, concise title summarizing the issue",
"bug_report_description": "Detailed description of the visual bug, including its appearance and potential impact on
gameplay",
"affected_item": "The specific game element (character, object, environment, UI) affected by the glitch"
}</code></pre>
            </div>
        </div>

        <div class="slide-content" , style="display: none;">
            <video src="assets/samples/bug_report_videos/2k08gd.mp4" style="width: 100%;" controls></video>


            <div style="margin-top: 1em; font-size: small;">
                <p>You are a video game quality assurance assistant who analyzes video clips to identify and document
                    visual glitches or strange behaviors. When presented with a video clip, carefully examine it for any
                    graphical bugs, rendering issues, physics anomalies, or unexpected events.</p>
                <br>

                <p>Provide your analysis in the following JSON format:</p>
                <br>
                <pre><code class="javascript">{
"reasoning": "Brief explanation of what you observe and why it appears to be a glitch",
"bug_report_title": "A clear, concise title summarizing the issue",
"bug_report_description": "Detailed description of the visual bug, including its appearance and potential impact on
gameplay",
"affected_item": "The specific game element (character, object, environment, UI) affected by the glitch"
}</code></pre>
            </div>
        </div>


        <p class="caption">
            Sample from the Bug Report Generation task.
        </p>
    </div>





    <div class="container blog main">
        <h1>Leaderboard</h1>
        <p>
            We evaluated a total of 11 proprietary and 5 open-weight models on <i>VideoGameQA-Bench</i>. Our
            evaluation
            includes both
            standard models and those designed for extended reasoning.</p>
    </div>

    <div class="container blog extra-large gray" id="dataset_comparison_table">
        <div class="table-wrapper">
            <table border="1" cellpadding="4" cellspacing="0">
                <caption style="text-align:left;">
                    Accuracy&nbsp;(%) scores of models on <em>VideoGameQA-Bench</em>.<br>
                    Tasks:&nbsp;Visual&nbsp;unit&nbsp;testing&nbsp;(VU);&nbsp;UI&nbsp;unit&nbsp;testing&nbsp;(UI);&nbsp;Visual&nbsp;regression&nbsp;testing&nbsp;(VR);&nbsp;Image-based&nbsp;glitch&nbsp;detection&nbsp;(IGD);&nbsp;Parametric&nbsp;clipping&nbsp;detection&nbsp;(PCD);&nbsp;Image-based&nbsp;bug-report&nbsp;generation&nbsp;(IBR);&nbsp;Video-based&nbsp;glitch&nbsp;detection&nbsp;(VGD);&nbsp;Needle-in-a-haystack&nbsp;(NIAH);&nbsp;Video-based&nbsp;bug-report&nbsp;generation&nbsp;(VBR).<br>
                    Scores marked with <sup>†</sup> were computed with the NIAH task set to&nbsp;0.
                    <strong>Total</strong> is the mean of the image-task and video-task averages.
                </caption>


                <thead>
                    <tr>
                        <th rowspan="2" scope="col"></th>
                        <th colspan="6" scope="colgroup">Image</th>
                        <th colspan="3" scope="colgroup">Video</th>
                        <th colspan="3" scope="colgroup">Average</th>
                    </tr>
                    <tr>
                        <th scope="col">VU</th>
                        <th scope="col">UI</th>
                        <th scope="col">VR</th>
                        <th scope="col">IGD</th>
                        <th scope="col">PCD</th>
                        <th scope="col">IBR</th>

                        <th scope="col">VGD</th>
                        <th scope="col">NIAH</th>
                        <th scope="col">VBR</th>

                        <th scope="col">Img.</th>
                        <th scope="col">Vid.</th>
                        <th scope="col">Total</th>
                    </tr>
                </thead>

                <tbody>
                    <!-- sample-count row -->
                    <tr>
                        <th scope="row"><em><strong>Model&nbsp;/&nbsp;#&nbsp;Samples</strong></em></th>
                        <td>100</td>
                        <td>100</td>
                        <td>250</td>
                        <td>1,000</td>
                        <td>686</td>
                        <td>100</td>
                        <td>100</td>
                        <td>1,000</td>
                        <td>100</td>
                        <td>2,236</td>
                        <td>1,200</td>
                        <td>3,436</td>
                    </tr>

                    <!-- commercial models -->
                    <tr>
                        <th scope="row">GPT-4o</th>
                        <td>43.0</td>
                        <td>28.0</td>
                        <td>28.8</td>
                        <td>81.3</td>
                        <td><strong>87.8</strong></td>
                        <td>51.0</td>
                        <td>75.8</td>
                        <td>19.0</td>
                        <td>51.0</td>
                        <td><strong>53.3</strong></td>
                        <td>48.6</td>
                        <td><strong>51.0</strong></td>
                    </tr>

                    <tr>
                        <th scope="row">GPT-4o&nbsp;Mini</th>
                        <td>42.0</td>
                        <td>30.0</td>
                        <td>20.4</td>
                        <td>76.8</td>
                        <td>66.9</td>
                        <td>46.0</td>
                        <td>71.8</td>
                        <td>10.0</td>
                        <td>26.0</td>
                        <td>47.0</td>
                        <td>35.9</td>
                        <td>41.5</td>
                    </tr>

                    <tr>
                        <th scope="row">GPT-4o&nbsp;Nano</th>
                        <td>9.0</td>
                        <td>14.0</td>
                        <td>19.2</td>
                        <td>57.0</td>
                        <td>66.9</td>
                        <td>16.0</td>
                        <td>49.1</td>
                        <td>4.0</td>
                        <td>14.0</td>
                        <td>30.4</td>
                        <td>22.4</td>
                        <td>26.4</td>
                    </tr>

                    <tr>
                        <th scope="row">GPT-4</th>
                        <td>39.0</td>
                        <td>23.0</td>
                        <td>31.6</td>
                        <td><strong>82.8</strong></td>
                        <td>82.5</td>
                        <td><strong>54.0</strong></td>
                        <td>57.0</td>
                        <td>1.0</td>
                        <td><strong>52.0</strong></td>
                        <td>52.2</td>
                        <td>36.7</td>
                        <td>44.4</td>
                    </tr>

                    <tr>
                        <th scope="row">o4-mini</th>
                        <td>50.0</td>
                        <td>35.0</td>
                        <td><strong>45.2</strong></td>
                        <td>76.4</td>
                        <td>65.0</td>
                        <td>38.0</td>
                        <td>70.0</td>
                        <td>18.0</td>
                        <td>28.0</td>
                        <td>51.6</td>
                        <td>38.7</td>
                        <td>45.1</td>
                    </tr>

                    <tr>
                        <th scope="row">o3</th>
                        <td>43.0</td>
                        <td>28.0</td>
                        <td>39.6</td>
                        <td>73.7</td>
                        <td>80.5</td>
                        <td>53.0</td>
                        <td>76.8</td>
                        <td>13.0</td>
                        <td>45.0</td>
                        <td>53.0</td>
                        <td>44.9</td>
                        <td>48.9</td>
                    </tr>

                    <tr>
                        <th scope="row">Gemini-2.5-Pro</th>
                        <td><strong>53.0</strong></td>
                        <td><strong>40.0</strong></td>
                        <td>30.8</td>
                        <td>75.4</td>
                        <td>72.2</td>
                        <td>33.0</td>
                        <td><strong>78.1</strong></td>
                        <td>34.0</td>
                        <td>36.0</td>
                        <td>50.7</td>
                        <td><strong>49.4</strong></td>
                        <td>50.0</td>
                    </tr>

                    <tr>
                        <th scope="row">Gemini-2.5-Flash</th>
                        <td>47.0</td>
                        <td>24.0</td>
                        <td>26.4</td>
                        <td>66.3</td>
                        <td>72.2</td>
                        <td>24.0</td>
                        <td>64.7</td>
                        <td>35.0</td>
                        <td>23.0</td>
                        <td>43.3</td>
                        <td>40.9</td>
                        <td>42.1</td>
                    </tr>

                    <tr>
                        <th scope="row">Gemini-2.0-Flash</th>
                        <td>44.0</td>
                        <td>28.0</td>
                        <td>12.0</td>
                        <td>68.1</td>
                        <td>78.0</td>
                        <td>20.0</td>
                        <td>54.5</td>
                        <td><strong>36.0</strong></td>
                        <td>26.0</td>
                        <td>41.7</td>
                        <td>38.8</td>
                        <td>40.3</td>
                    </tr>

                    <tr>
                        <th scope="row">Sonnet 3.7</th>
                        <td>23.0</td>
                        <td>22.0</td>
                        <td>24.0</td>
                        <td>65.1</td>
                        <td>76.4</td>
                        <td>29.0</td>
                        <td>66.9</td>
                        <td>31.0</td>
                        <td>22.0</td>
                        <td>39.9</td>
                        <td>40.0</td>
                        <td>39.9</td>
                    </tr>

                    <tr>
                        <th scope="row">Sonnet 3.5</th>
                        <td>23.0</td>
                        <td>29.0</td>
                        <td>14.0</td>
                        <td>70.1</td>
                        <td>72.9</td>
                        <td>33.0</td>
                        <td>61.2</td>
                        <td>27.0</td>
                        <td>26.0</td>
                        <td>40.3</td>
                        <td>38.1</td>
                        <td>39.2</td>
                    </tr>

                    <!-- open-source models -->
                    <tr>
                        <th scope="row">Llama-4.0-Scout</th>
                        <td>32.0</td>
                        <td>23.0</td>
                        <td>13.6</td>
                        <td>55.8</td>
                        <td>71.6</td>
                        <td>8.0</td>
                        <td>58.6</td>
                        <td>&mdash;</td>
                        <td>5.0</td>
                        <td>34.0</td>
                        <td>21.2<sup>†</sup></td>
                        <td>27.6<sup>†</sup></td>
                    </tr>

                    <tr>
                        <th scope="row">Llama-4.0-Maverick</th>
                        <td>21.0</td>
                        <td>22.0</td>
                        <td>18.4</td>
                        <td>53.2</td>
                        <td>65.7</td>
                        <td>7.0</td>
                        <td>56.6</td>
                        <td>&mdash;</td>
                        <td>15.0</td>
                        <td>31.2</td>
                        <td>23.9<sup>†</sup></td>
                        <td>27.5<sup>†</sup></td>
                    </tr>

                    <tr>
                        <th scope="row">Gemma&nbsp;(27&nbsp;B)</th>
                        <td>12.0</td>
                        <td>12.0</td>
                        <td>12.8</td>
                        <td>46.7</td>
                        <td>69.7</td>
                        <td>10.0</td>
                        <td>51.3</td>
                        <td>&mdash;</td>
                        <td>9.0</td>
                        <td>27.2</td>
                        <td>20.1<sup>†</sup></td>
                        <td>23.6<sup>†</sup></td>
                    </tr>

                    <tr>
                        <th scope="row">Mistral-Small-3.1 (24B)</th>
                        <td>15.0</td>
                        <td>17.0</td>
                        <td>25.6</td>
                        <td>59.7</td>
                        <td>62.5</td>
                        <td>9.0</td>
                        <td>61.4</td>
                        <td>&mdash;</td>
                        <td>14.0</td>
                        <td>31.5</td>
                        <td>25.1<sup>†</sup></td>
                        <td>28.3<sup>†</sup></td>
                    </tr>

                    <tr>
                        <th scope="row">Qwen-2.5-VL (72B)</th>
                        <td>38.0</td>
                        <td>27.0</td>
                        <td>21.2</td>
                        <td>70.0</td>
                        <td>76.0</td>
                        <td>19.0</td>
                        <td>47.9</td>
                        <td>&mdash;</td>
                        <td>17.0</td>
                        <td>41.9</td>
                        <td>21.6<sup>†</sup></td>
                        <td>31.7<sup>†</sup></td>
                    </tr>
                </tbody>
            </table>
        </div>
        <p></p>
    </div>











    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed
                by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>
    </footer>


    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>
    <script src="assets/scripts/main.js"></script>

</html>
</body>